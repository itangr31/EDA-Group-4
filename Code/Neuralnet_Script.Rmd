---
title: "Neuralnet_WindForecast"
output: html_document
date: "2022-12-02"
---

```{r}
#PART 1 : Load Packages

library(tidyverse)
library(lubridate)
library(neuralnet)
library(MLmetrics)
library(hydroGOF)
library(DTWBI)
library(plyr)

```

```{r}
#PART 2 : Load Datasets for Single Turbine

Turbine2016 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2016-06-06_-_2017-01-01_1042.csv", skip = 9)
Turbine2017 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2017-01-01_-_2018-01-01_1042.csv", skip = 9)
Turbine2018 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2018-01-01_-_2019-01-01_1042.csv", skip = 9)
Turbine2019 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2019-01-01_-_2020-01-01_1042.csv", skip = 9)
Turbine2020 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2020-01-01_-_2021-01-01_1042.csv", skip = 9)
Turbine2021 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2021-01-01_-_2021-07-01_1042.csv", skip = 9)


Turbine<- rbind(Turbine2020, Turbine2021)
Turbine <- Turbine2016






```

```{r}
#PART 3 : Data-processing

#Convert timestamp variable to time
Turbine <- rename(Turbine, Date.and.time = X..Date.and.time)
Turbine<-Turbine%>%
  mutate(date=ymd_hms(Date.and.time))


#Extract value from timestamp into new variables
Turbine2<-Turbine%>%
  mutate(hour=hour(date))%>%
  mutate(year=year(date))%>%
  mutate(month=month(date))%>%
  mutate(day=day(date))%>%
  mutate(week=week(date))

Turbine2<-Turbine2%>%
  mutate(sinmonth = sin(2 * pi * month / 12),
         cosmonth = cos(2 * pi * month / 12),
         sinday = sin(2 * pi * day / 7),
         cosday = cos(2 * pi * day / 7),
         cosweek = cos(2* pi * week / 52),
         sinweek = sin(2 * pi * week / 52),
         sinhour = sin(2 * pi * hour / 24),
         coshour = cos(2 * pi * hour / 24))

#Create new final dataset with relevant variables
Turbine3<-Turbine2[c(1, 2, 4, 5, 16, 28, 17,95, 302:314)]

#Convert timestamp variable to time
Turbine3<-Turbine3%>%
  mutate(date=lubridate::ymd_hms(Date.and.time))

#Create test and train data

train_features <- Turbine3 %>% 
  select(!c(Date.and.time,date,year))%>% 
  colnames()

Turbine3<-Turbine3%>%
  drop_na()

split_point <- "2016-10-15 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))

maxs <- apply(Turbine3[train_features], 2, max)
mins <- apply(Turbine3[train_features], 2, min)

scaled_Turbine3 <- as.data.frame(scale(Turbine3[train_features], center = mins, scale = maxs - mins))

scaled_Turbine3$date <- Turbine3$date

train_data <- scaled_Turbine3 %>% subset(date < split_point)
test_data <- scaled_Turbine3 %>% subset(date >= split_point)

```

```{r}
#PART 4 Model Deployment


nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula, 
                data = train_data, hidden = 8, linear.output = TRUE,err.fct = "sse", threshold =0.5, algorithm = "rprop+",stepmax = 1e+5)
plot(nn)


```

```{r}
#PART 5 Neural Network

#Prediction
nn_predictions <- compute(nn, test_data)

predictions <- data.frame(
  date = test_data$date,
  normalized = nn_predictions$net.result,
  denormalized = nn_predictions$net.result *(max(Turbine3$Energy.Export..kWh.)-min(Turbine3$Energy.Export..kWh.))+min(Turbine3$Energy.Export..kWh.)
)

#Plot actual vs predicted

ggplot(dplyr::filter(Turbine3, date >="2016-10-20 00:00:00", date <="2016-10-20 23:00:00"),
       aes(x = date, y = Energy.Export..kWh.)) +
  geom_line() +
  geom_line(aes(y = denormalized), color = "red", alpha = 0.5,
            data = filter(predictions, date >="2016-10-20 00:00:00", date <="2016-10-20 23:00:00" )) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(x = "Date", y = "Energy Export (kWh)",
       title = " Actual vs Prediction",
       subtitle = "Actual = black; Prediction = red ")
```
```{r}
#PART 6 Parameter Tuning

#Cross Validation

train_data <- read.csv("Data/finaltrain.csv")
test_data <- read.csv("Data/finaltest.csv")

train_data <- train_data %>% 
  mutate(date=dmy_hm(Date.and.time)) %>% 
  dplyr::select(!Date.and.time) %>% 
  drop_na()

test_data <- test_data %>% 
  mutate(date=dmy_hm(Date.and.time)) %>% 
  dplyr::select(!Date.and.time) %>% 
  drop_na()

Turbine <- rbind(train_data,test_data)

Turbine <- Turbine %>% 
  drop_na()

clean_features <- Turbine %>% 
  dplyr::select(!date)%>% 
  colnames()

train_features <- Turbine %>% 
  dplyr::select(!c(date,Energy.Export..kWh.))%>% 
  colnames()

crossvalidate <- function(data,hidden_l=c(5))
{
    
    # Scaling the data (min-max scaling)
maxs <- apply(data[clean_features], 2, max)
mins <- apply(data[clean_features], 2, min)

scaled <- as.data.frame(scale(data[clean_features], center = mins, scale = maxs - mins))

    
    # Initialize cv.error vector
    cv.error <- NULL
    
    # Number of train-test splits
    k <- 10
    
# Cross validating
    for(j in 1:k)
    {
        # Train-test split
        index <- sample(1:nrow(data),round(0.90*nrow(data)))
        train.cv <- scaled[index,]
        test.cv <- scaled[-index,]
        
        # NN fitting
        nn <- neuralnet(nn_formula,data=train.cv,hidden=hidden_l,linear.output = TRUE,err.fct = "sse", threshold =0.5, algorithm = "rprop+")
        
        # Predicting
        pr.nn <- compute(nn,test.cv)
        
        # Scaling back the predicted results
        pr.nn <- pr.nn$net.result*(max(Turbine$Energy.Export..kWh.)-min(Turbine$Energy.Export..kWh.))+min(Turbine$Energy.Export..kWh.)
        
        # Real results
        test.cv.r <- (test.cv$Energy.Export..kWh.)*(max(Turbine$Energy.Export..kWh.)-min(Turbine$Energy.Export..kWh.))+min(Turbine$Energy.Export..kWh.)
        
        # Calculating MSE test error
        cv.error <- sum((test.cv.r - pr.nn)^2)/nrow(test.cv)
    }
    
    # Return average MSE
    return(mean(cv.error))
}

# Selecting the number of neurons in the hidden layer

test.error <- NULL
train.error <- NULL

#Normalize Data

maxs <- apply(Turbine[clean_features], 2, max)
mins <- apply(Turbine[clean_features], 2, min)

scaled_train <- as.data.frame(scale(train_data[clean_features], center = mins, scale = maxs - mins)) 
scaled_test <- as.data.frame(scale(test_data[clean_features], center = mins, scale = maxs - mins))

nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))

#Generate Progress Bar
pbar <- create_progress_bar('text')
pbar$init(12)


set.seed(123)

for(i in 1:12)
{
   # Fit the net and calculate training error (point estimate)
  nn.fit <- neuralnet(nn_formula, 
                data = scaled_train, hidden = c(i), linear.output = TRUE,err.fct = "sse", threshold =0.5, algorithm = "rprop+")
  
  train.error[i] <- sum(((as.data.frame(nn.fit$net.result)*(412-0)+412) - (scaled_train$Energy.Export..kWh.*(412-0)+412))^2)/nrow(scaled_train)
  
  # Calculate test error through cross validation
    test.error[i] <- crossvalidate(Turbine,hidden_l=c(i))
    
    # Step bar
    pbar$step()

}

# Print out test and train error vectors
test.error
train.error

# Plot train error
plot(train.error,main='MSE vs hidden neurons',xlab="Hidden neurons",ylab='Train error MSE',type='l',col='red',lwd=2)
# Plot test error
plot(test.error,main='MSE vs hidden neurons',xlab="Hidden neurons",ylab='Test error MSE',type='l',col='blue',lwd=2)

```

```{r}
# PART 7 Code using Final Dataset

#Data processing


train_data <- read.csv("Data/finaltrain.csv")
test_data <- read.csv("Data/finaltest.csv")

train_data <- train_data %>% 
  mutate(date=dmy_hm(Date.and.time)) %>% 
  dplyr::select(!Date.and.time) %>% 
  drop_na()

test_data <- test_data %>% 
  mutate(date=dmy_hm(Date.and.time)) %>% 
  dplyr::select(!Date.and.time) %>% 
  drop_na()

Turbine <- rbind(train_data,test_data)

Turbine <- Turbine %>% 
  drop_na()

train_features <- Turbine %>% 
  dplyr::select(!date)%>% 
  colnames()

#Normalize Data

maxs <- apply(Turbine[train_features], 2, max)
mins <- apply(Turbine[train_features], 2, min)

scaled_train <- as.data.frame(scale(train_data[train_features], center = mins, scale = maxs - mins))
scaled_test <- as.data.frame(scale(test_data[train_features], center = mins, scale = maxs - mins))

#Model Generation

nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula, 
                data = scaled_train, hidden = 8, linear.output = TRUE,err.fct = "sse", threshold =0.1, algorithm = "rprop+",stepmax = 1e+5)

plot(nn)

nn_predictions <- compute(nn, scaled_test)

predictions <- data.frame(
  date = test_data$date,
  prediction = nn_predictions$net.result *(max(Turbine$Energy.Export..kWh.)-min(Turbine$Energy.Export..kWh.))+min(Turbine$Energy.Export..kWh.),
  actual = test_data$Energy.Export..kWh.
)

#Plot actual vs predicted

random_date <- "2020-05-25"

plot1 <- predictions %>% 
  pivot_longer(!date, names_to = "data_type", values_to = "number" ) %>% 
  filter(date(date) == "2020-05-25") %>% 
  ggplot() +
  geom_line(aes(x = date, y = number, colour = data_type, alpha =0.7)) +
  geom_point(aes(x = date, y = number, colour = data_type, shape = data_type)) +
  theme_minimal() +
  theme(legend.position = "right") +
  labs(x = "Date", y = "Energy Export (kWh)",
       title = " Actual vs Prediction")

plot1



```
```{r}
#error function

#Calculate MAPE

predictions$APE<-abs((predictions$actual - predictions$prediction)/predictions$actual) * 100

predictions<-predictions%>%
  filter_at(vars(APE), all_vars(!is.infinite(.)))

MAPE <- mean(predictions$APE)
#Calculate RMSE

RMSE <- RMSE(y_pred = predictions$prediction, y_true = predictions$actual)

NRMSE <- nrmse(predictions$prediction, predictions$actual)

#Calculate MAE

MAE <- MAE(y_pred = predictions$prediction, y_true = predictions$actual)

NMAE <- compute.nmae(predictions$prediction, predictions$actual)

predictions %>% 
  select(-actual) %>% 
  write.csv("/Users/ilhamrizaldi/Documents/GitHub/ANN Prediction.csv", row.names=FALSE)

```



