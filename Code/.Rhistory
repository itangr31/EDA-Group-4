list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
Turbine3$normalized <- (Turbine3$Energy.Export..kWh. - normalization_constants$mean)/normalization_constants$std.dev
train_data <- which(Turbine3$date < split_point)
test_data <- which(Turbine3$date <- split_point)
train_data <- which(Turbine3$date < split_point)
test_data <- which(Turbine3$date <- split_point)
test_data <- which(Turbine3$date <- split_point)
train_data <- which(Turbine3$date < split_point)
test_data <- which(Turbine3$date >= split_point)
train_data <- subset(Turbine3, Turbine3$date < split_point)
train_data <- Turbine3 %>% filter(date < split_point)
train_data <- Turbine3 %>% filter(date < split_point)
library(tidyverse)
library(lubridate)
library(neuralnet)
Turbine2016 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2016-06-06_-_2017-01-01_1042.csv", skip = 9)
Turbine2016 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2016-06-06_-_2017-01-01_1042.csv", skip = 9)
Turbine2017 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2017-01-01_-_2018-01-01_1042.csv", skip = 9)
Turbine2018 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2018-01-01_-_2019-01-01_1042.csv", skip = 9)
Turbine2019 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2019-01-01_-_2020-01-01_1042.csv", skip = 9)
Turbine2020 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2020-01-01_-_2021-01-01_1042.csv", skip = 9)
Turbine2021 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2021-01-01_-_2021-07-01_1042.csv", skip = 9)
Turbine2021 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2021-01-01_-_2021-07-01_1042.csv", skip = 9)
Turbine<- rbind(Turbine2020, Turbine2021)
#Convert timestamp variable to time
Turbine <- rename(Turbine, Date.and.time = X..Date.and.time)
Turbine<-Turbine%>%
mutate(date=ymd_hms(Date.and.time))
#Extract value from timestamp into new variables
Turbine2<-Turbine%>%
mutate(hour=hour(date))%>%
mutate(year=year(date))%>%
mutate(month=month(date))%>%
mutate(day=day(date))%>%
mutate(week=week(date))
Turbine2<-Turbine2%>%
mutate(sinmonth = sin(2 * pi * month / 12),
cosmonth = cos(2 * pi * month / 12),
sinday = sin(2 * pi * day / 7),
cosday = cos(2 * pi * day / 7),
cosweek = cos(2* pi * week / 52),
sinweek = sin(2 * pi * week / 52),
sinhour = sin(2 * pi * hour / 24),
coshour = cos(2 * pi * hour / 24))
#Create new final dataset with relevant variables
Turbine3<-Turbine2[c(1, 2, 4, 5, 16, 28, 17,95, 302:314)]
#Convert timestamp variable to time
Turbine3<-Turbine3%>%
mutate(date=lubridate::ymd_hms(Date.and.time))
Turbine3<-Turbine3%>%
drop_na()
split_point <- "2021-02-22 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
Turbine3$normalized <- (Turbine3$Energy.Export..kWh. - normalization_constants$mean)/normalization_constants$std.dev
train_data <- Turbine3 %>% subset(date < split_point)
test_data <- Turbine3 %>% subset(date >= split_point)
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
train_features <- colnames(Turbine3)
train_features <- Turbine3 %>%
colnames(select(!c(Date.and.time,date)))
train_features <- Turbine3 %>%
colnames(select(!date)))
train_features <- Turbine3 %>%
colnames(select(!date))
colnames(select(!c("Date.and.time","date")
train_features <- Turbine3 %>%
?select
train_features <- Turbine3 %>%
select(!c(Date.and.time,date)) %>%
colnames()
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 1, linear.output = TRUE, algorithm = "sag")
nn <- neuralnet(nn_formula,
data = train_data, hidden = 1, linear.output = TRUE, algorithm = "sag")
nn <- neuralnet(nn_formula,
data = train_data, hidden = 1, linear.output = TRUE, algorithm = "sag", stepmax = 1e05)
plot(nn)
#Prediction
nn_predictions <- as.numeric(neuralnet::compute(nn, test_data[train_features])$net.result)
#Re-scale predictions with date
predictions <- data.frame(
date = test_data$date,
normalized = nn_predictions,
denormalized = (nn_predictions * normalization_constants$std.dev) + normalization_constants$mean
)
nn <- neuralnet(nn_formula,
data = train_data, hidden = 5, linear.output = TRUE, algorithm = "sag", stepmax = 1e05)
plot(nn)
#Prediction
nn_predictions <- as.numeric(neuralnet::compute(nn, test_data[train_features])$net.result)
#Re-scale predictions with date
predictions <- data.frame(
date = test_data$date,
normalized = nn_predictions,
denormalized = (nn_predictions * normalization_constants$std.dev) + normalization_constants$mean
)
View(predictions)
View(train_data)
#Prediction
nn_predictions <- as.numeric(neuralnet::compute(nn, test_data[train_features])$net.result)
#Re-scale predictions with date
predictions <- data.frame(
date = test_data$date,
normalized = nn_predictions,
denormalized = (nn_predictions * normalization_constants$std.dev) + normalization_constants$mean
)
View(Turbine3)
View(test_data)
View(train_data)
n_train_data <- train_data %>%
as.data.frame(lapply(train_features,normalize))
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
n_train_data <- train_data %>%
as.data.frame(lapply(train_features,normalize))
n_train_data <- train_data %>%
as.data.frame(lapply(normalize))
n_train_data <- train_data %>%
select(!c(Date.and.time,date)) %>%
as.data.frame(lapply(normalize))
n_train_data <- train_data %>%
select(!c(Date.and.time,date))
n_train_data <- as.data.frame(lapply(n_train_data,normalize))
n_test_data <- test_data %>%
select(!c(Date.and.time,date))
n_test_data <- as.data.frame(lapply(n_test_data,normalize))
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = train_data, hidden = 10, linear.output = TRUE, algorithm = "sag", stepmax = 1e05)
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag", stepmax = 1e05)
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag", stepmax = 1e09)
n_test_data[train_features]
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag", stepmax = 1e+06)
install.packages("GuessCompx")
Turbine <- Turbine2016
library(lubridate)
library(neuralnet)
Turbine2016 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2016-06-06_-_2017-01-01_1042.csv", skip = 9)
Turbine <- Turbine2016
#Convert timestamp variable to time
Turbine <- rename(Turbine, Date.and.time = X..Date.and.time)
Turbine<-Turbine%>%
mutate(date=ymd_hms(Date.and.time))
#Extract value from timestamp into new variables
Turbine2<-Turbine%>%
mutate(hour=hour(date))%>%
mutate(year=year(date))%>%
mutate(month=month(date))%>%
mutate(day=day(date))%>%
mutate(week=week(date))
Turbine2<-Turbine2%>%
mutate(sinmonth = sin(2 * pi * month / 12),
cosmonth = cos(2 * pi * month / 12),
sinday = sin(2 * pi * day / 7),
cosday = cos(2 * pi * day / 7),
cosweek = cos(2* pi * week / 52),
sinweek = sin(2 * pi * week / 52),
sinhour = sin(2 * pi * hour / 24),
coshour = cos(2 * pi * hour / 24))
#Create new final dataset with relevant variables
Turbine3<-Turbine2[c(1, 2, 4, 5, 16, 28, 17,95, 302:314)]
#Convert timestamp variable to time
Turbine3<-Turbine3%>%
mutate(date=lubridate::ymd_hms(Date.and.time))
Turbine3<-Turbine3%>%
drop_na()
split_point <- "2021-02-22 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
View(Turbine3)
Turbine3<-Turbine3%>%
drop_na()
split_point <- "2016-10-15 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
Turbine3$normalized <- (Turbine3$Energy.Export..kWh. - normalization_constants$mean)/normalization_constants$std.dev
train_data <- Turbine3 %>% subset(date < split_point)
test_data <- Turbine3 %>% subset(date >= split_point)
train_features <- Turbine3 %>%
select(!c(Date.and.time,date)) %>%
colnames()
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
n_train_data <- train_data %>%
select(!c(Date.and.time,date))
n_train_data <- as.data.frame(lapply(n_train_data,normalize))
n_test_data <- test_data %>%
select(!c(Date.and.time,date))
n_test_data <- as.data.frame(lapply(n_test_data,normalize))
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag", stepmax = 1e+06)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag")
Turbine3<-Turbine3%>%
drop_na()
split_point <- "2016-10-15 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
Turbine3$normalized <- (Turbine3$Energy.Export..kWh. - normalization_constants$mean)/normalization_constants$std.dev
train_data <- Turbine3 %>% subset(date < split_point)
test_data <- Turbine3 %>% subset(date >= split_point)
train_features <- Turbine3 %>%
select(!c(Date.and.time,date)) %>%
colnames()
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
n_train_data <- train_data %>%
select(!c(Date.and.time,date))
n_train_data <- as.data.frame(lapply(n_train_data,normalize))
n_test_data <- test_data %>%
select(!c(Date.and.time,date))
n_test_data <- as.data.frame(lapply(n_test_data,normalize))
View(n_train_data)
Turbine3<-Turbine3%>%
drop_na()
split_point <- "2016-10-15 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
train_data <- Turbine3 %>% subset(date < split_point)
test_data <- Turbine3 %>% subset(date >= split_point)
train_features <- Turbine3 %>%
select(!c(Date.and.time,date)) %>%
colnames()
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
n_train_data <- train_data %>%
select(!c(Date.and.time,date))
n_train_data <- as.data.frame(lapply(n_train_data,normalize))
n_test_data <- test_data %>%
select(!c(Date.and.time,date))
n_test_data <- as.data.frame(lapply(n_test_data,normalize))
```{r}
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag")
sum(is.na(n_train_data))
library(tidyverse)
library(lubridate)
library(neuralnet)
Turbine2016 <- read.csv("Data/Turbine_Data_Penmanshiel_01_2016-06-06_-_2017-01-01_1042.csv", skip = 9)
Turbine <- Turbine2016
#Convert timestamp variable to time
Turbine <- rename(Turbine, Date.and.time = X..Date.and.time)
Turbine<-Turbine%>%
mutate(date=ymd_hms(Date.and.time))
#Extract value from timestamp into new variables
Turbine2<-Turbine%>%
mutate(hour=hour(date))%>%
mutate(year=year(date))%>%
mutate(month=month(date))%>%
mutate(day=day(date))%>%
mutate(week=week(date))
Turbine2<-Turbine2%>%
mutate(sinmonth = sin(2 * pi * month / 12),
cosmonth = cos(2 * pi * month / 12),
sinday = sin(2 * pi * day / 7),
cosday = cos(2 * pi * day / 7),
cosweek = cos(2* pi * week / 52),
sinweek = sin(2 * pi * week / 52),
sinhour = sin(2 * pi * hour / 24),
coshour = cos(2 * pi * hour / 24))
#Create new final dataset with relevant variables
Turbine3<-Turbine2[c(1, 2, 4, 5, 16, 28, 17,95, 302:314)]
#Convert timestamp variable to time
Turbine3<-Turbine3%>%
mutate(date=lubridate::ymd_hms(Date.and.time))
Turbine3<-Turbine3%>%
drop_na()
split_point <- "2016-10-15 00:00:00"
table(ifelse(Turbine3$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = Turbine3$Energy.Export..kWh.[Turbine3$date < split_point])
)
train_data <- Turbine3 %>% subset(date < split_point)
test_data <- Turbine3 %>% subset(date >= split_point)
train_features <- Turbine3 %>%
select(!c(Date.and.time,date)) %>%
colnames()
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
n_train_data <- train_data %>%
select(!c(Date.and.time,date))
View(n_train_data)
n_train_data <- as.data.frame(lapply(n_train_data,normalize))
n_train_data <- train_data %>%
select(!c(Date.and.time,date,year))
n_train_data <- as.data.frame(lapply(n_train_data,normalize))
n_test_data <- test_data %>%
select(!c(Date.and.time,date,year))
n_test_data <- as.data.frame(lapply(n_test_data,normalize))
train_features <- Turbine3 %>%
select(!c(Date.and.time,date,year)) %>%
colnames()
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag")
View(n_train_data)
plot(nn)
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag", stepmax = 1e05)
#PART 4 Model Deployment
set.seed(123)
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2, linear.output = TRUE, algorithm = "sag", stepmax = 1e06)
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2,learningrate.limit = NULL,learningrate.factor = list(minus =0.5, plus = 0.12), algorithm = "rprop+")
nn <- neuralnet(nn_formula,
data = n_train_data, hidden = 2,learningrate.limit = NULL,learningrate.factor = list(minus =0.5, plus = 0.12), algorithm = "rprop+", stepmax =1e+05)
plot(nn)
View(normalization_constants)
#PART 1 : Load Packages
library(tidyverse)
library(lubridate)
library(neuralnet)
train_data <- read.csv("Data/finaltrain.csv")
test_data <- read.csv("Data/finaltest.csv")
train_data <- train_data %>%
mutate(date=dmy_hm(Date.and.time)) %>%
select(!Date.and.time) %>%
drop_na()
test_data <- test_data %>%
mutate(date=dmy_hm(Date.and.time)) %>%
select(!Date.and.time) %>%
drop_na()
Turbine <- rbind(train_data,test_data)
Turbine <- Turbine %>%
drop_na()
train_features <- Turbine %>%
select(!date)%>%
colnames()
maxs <- apply(Turbine[train_features], 2, max)
mins <- apply(Turbine[train_features], 2, min)
scaled_train <- as.data.frame(scale(train_data[train_features], center = mins, scale = maxs - mins))
scaled_test <- as.data.frame(scale(test_data[train_features], center = mins, scale = maxs - mins))
#Model Generation
nn_formula <- as.formula(paste("Energy.Export..kWh. ~", paste(train_features, collapse = "+")))
nn <- neuralnet(nn_formula,
data = scaled_train, hidden = 3, linear.output = TRUE,err.fct = "sse", threshold =0.1, stepmax = 1e+5)
plot(nn)
nn_predictions <- compute(nn, scaled_test)
predictions <- data.frame(
date = test_data$date,
prediction = nn_predictions$net.result *(max(Turbine$Energy.Export..kWh.)-min(Turbine$Energy.Export..kWh.))+min(Turbine$Energy.Export..kWh.),
actual = test_data$Energy.Export..kWh.
)
#Plot actual vs predicted
random_date <- sample(unique(date(predictions$date)), 1)
predictions <- predictions %>%
pivot_longer(!date, names_to = "data_type", values_to = "number" )
plot1 <- predictions %>%
filter(date(date) == random_date) %>%
ggplot() +
geom_line(aes(x = date, y = number, colour = data_type)) +
geom_point(aes(x = date, y = number, colour = data_type, shape = data_type)) +
theme_minimal() +
theme(legend.position = "right") +
labs(x = "Date", y = "Energy Export (kWh)",
title = " Actual vs Prediction")
plot1
predict= select(predictions, data_type == "prediction")
act=select(predictions, data_type == "actual")
predict= select(predictions, data_type == "prediction")
View(predictions)
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act-predict)/act)
View(predict)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(deviation))
accuracy
accuracy=1-abs(mean(comparison$deviation))
accuracy
comparison=data.frame(predict$number,act$number,deviation)
View(comparison)
mean(comparison$deviation)
View(comparison)
sum(comparison$deviation)
View(comparison)
mean(deviation)
deviation
comparison$deviation
mean(predict$number)
mean(deviation)
is.na(deviation)
sum(is.na(deviation))
accuracy=1-abs(mean(na.omit(deviation))
accuracy=1-abs(mean(na.omit(deviation)))
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
sum(is.nan(deviation))
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
predict= filter(predictions, data_type == "prediction")
act=filter(predictions, data_type == "actual")
comparison=data.frame(predict,act)
deviation=((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-abs(mean(na.omit(deviation)))
accuracy
accuracy=1-abs(mean(deviation))
accuracy=1-mean(abs(deviation))
accuracy
deviation=abs((act$number-predict$number)/act$number))
deviation=abs((act$number-predict$number)/act$number)))
deviation=abs((act$number-predict$number)/act$number))
deviation=abs((act$number-predict$number)/act$number)))
?abs
deviation=abs((act$number-predict$number)/act$number))
deviation=abs((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-(abs(deviation))
accuracy
accuracy=1-mean(deviation)
accuracy
deviation=abs((act$number-predict$number)/act$number)
comparison=data.frame(predict$number,act$number,deviation)
accuracy=1-mean(deviation)
accuracy
accuracy=1-sum(deviation)
accuracy
